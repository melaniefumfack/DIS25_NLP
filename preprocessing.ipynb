{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Topic Gender Bias in ESUPOL (BTW17)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#import pandas as pd\n",
    "os.environ['MODIN_ENGINE'] = 'dask'\n",
    "import modin.pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('german')\n",
    "\n",
    "from HanTa import HanoverTagger as ht\n",
    "tagger = ht.HanoverTagger('./morphmodel_ger.pgz')\n",
    "\n",
    "from genderize import Genderize\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "from functions import preprocessing\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns=500\n",
    "pd.options.display.width = 5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_path = 'G:\\dis25'\n",
    "all_files = glob.glob(source_path + '/*.csv')[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load first slice of btw17 dataset into a Pandas DataFrame\n",
    "#### Load only the raw_data columns\n",
    "*the first slice was handled separately since it's the only one with headers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4464/550357359.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m \u001B[1;33m**\u001B[0m \u001B[1;36m6\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mchunks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'suggestions_20210719.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mchunksize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0musecols\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'raw_data'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mbtw17_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchunk\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mchunks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 6\n",
    "chunks = pd.read_csv(os.path.join(source_path,'suggestions_20210719.csv'), chunksize=chunksize, usecols=['raw_data'])\n",
    "btw17_df = pd.concat(chunk for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extract the raw data column and save th DataFrame to a separate file\n",
    "- *The queryterms were removed from the suggestions*\n",
    "- *The queryterms only include the firstname now*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "btw17_df = pd.DataFrame(btw17_df.raw_data.apply(lambda x: json.loads(x)).to_list(),columns=['queryterm','suggestions',3,4,5])[['queryterm','suggestions']]\n",
    "btw17_df['suggestions'] = btw17_df.apply(lambda x: [suggestion.replace(x.queryterm.lower(), '') for suggestion in x.suggestions], axis=1)\n",
    "btw17_df['queryterm'] = btw17_df.queryterm.apply(lambda x: x.split(' ')[0].split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "btw17_df = pd.to_csv('./raw_suggestions_20210719.csv', usecols=['queryterm','suggestions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the other Dataset slices, proceed as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chunksize = 10 ** 6\n",
    "for i in range(42,63):\n",
    "    chunks = pd.read_csv(all_files[i],\n",
    "                         header=None,\n",
    "                         names=['id','queryterm','date','client','lang','url','raw_data'],\n",
    "                         usecols=['raw_data'],\n",
    "                         chunksize=chunksize)\n",
    "    temp_df = pd.concat(chunks)\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_df.raw_data.apply(lambda x: json.loads(x)).to_list(),columns=['queryterm','suggestions',3,4,5])[['queryterm','suggestions']]\n",
    "    temp_df['suggestions'] = temp_df.apply(lambda x: [suggestion.replace(x.queryterm.lower(), '').strip() for suggestion in x.suggestions], axis=1)\n",
    "    temp_df['queryterm'] = temp_df.queryterm.apply(lambda x: x.split(' ')[0].split('-')[0])\n",
    "\n",
    "\n",
    "    temp_df.to_csv('./raw_'+all_files[i].split('\\\\')[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get a list of all firstnames\n",
    "- *During the process duplicates were removed at multiple points to reduce computing efforts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_raw_df = glob.glob('./raw_suggestions*')\n",
    "name_list = []\n",
    "for i in all_raw_df:\n",
    "    chunks = pd.read_csv(i,\n",
    "                         usecols=['queryterm','suggestions'],\n",
    "                         chunksize=chunksize)\n",
    "    btw17_rawdata_df = btw17_rawdata_df.append(pd.concat(chunks))\n",
    "    name_list.extend(btw17_rawdata_df.queryterm.drop_duplicates().to_list())\n",
    "    name_list = list(set(name_list))\n",
    "print(len(name_list))\n",
    "name_list[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Genderize.io API\n",
    "> This API supports access to a database of hundreds of thousand names in various notations\n",
    "> It takes a list of name as input, sends a request to the Genderize.io server and delivers a\n",
    "> list containing a dictionary for each requested name listing a count, the gender (male/female/None) and a probability.\n",
    ">\n",
    "> However the number of requests per day is limited to 1000 (per IP address).\n",
    "> This isn't a problem for us though since we've got 326 unique names in the btw17 dataset\n",
    "> and XX unique names in the eu dataset.\n",
    "\n",
    "### Get gender for each name and create a DataFrame\n",
    "n\t2017-02-13 17:13:46\tfirefox\tde\thttp://clients1.google.de/complete/search\t[\"Jan van Aken\",[\"jan van aken\",\"jan van aken ...\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gender_list_btw17 = Genderize().get(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'count': 2406, 'gender': 'male', 'name': 'Gunnar', 'probability': 0.99},\n",
      " {'count': 755, 'gender': 'male', 'name': 'Ates', 'probability': 0.9},\n",
      " {'count': 1, 'gender': 'male', 'name': 'bundeskanzlerin', 'probability': 1.0},\n",
      " {'count': 245870, 'gender': 'male', 'name': 'Michael', 'probability': 0.99},\n",
      " {'count': 16593, 'gender': 'male', 'name': 'Maurice', 'probability': 0.98},\n",
      " {'count': 787, 'gender': 'male', 'name': 'Shen', 'probability': 0.65},\n",
      " {'count': 57806, 'gender': 'male', 'name': 'Florian', 'probability': 0.99},\n",
      " {'count': 38513, 'gender': 'female', 'name': 'Renata', 'probability': 0.99},\n",
      " {'count': 501011, 'gender': 'male', 'name': 'David', 'probability': 0.99},\n",
      " {'count': 1, 'gender': 'male', 'name': 'jungeunion', 'probability': 1.0},\n",
      " {'count': 11677, 'gender': 'male', 'name': 'Franz', 'probability': 0.97},\n",
      " {'count': 1028, 'gender': 'male', 'name': 'von', 'probability': 0.75},\n",
      " {'count': 41244, 'gender': 'male', 'name': 'Jimmy', 'probability': 0.98},\n",
      " {'count': 12170, 'gender': 'male', 'name': 'Bernd', 'probability': 0.99},\n",
      " {'count': 0, 'gender': None, 'name': 'dobrindt', 'probability': 0.0},\n",
      " {'count': 58, 'gender': 'male', 'name': 'Sigmar', 'probability': 0.98},\n",
      " {'count': 4428, 'gender': 'male', 'name': 'Gerd', 'probability': 0.93},\n",
      " {'count': 1578, 'gender': 'female', 'name': 'Sybille', 'probability': 0.98},\n",
      " {'count': 229433, 'gender': 'female', 'name': 'Marie', 'probability': 0.98},\n",
      " {'count': 45829, 'gender': 'male', 'name': 'Rafael', 'probability': 0.99},\n",
      " {'count': 9, 'gender': 'male', 'name': 'Bartholomäus', 'probability': 1.0},\n",
      " {'count': 19741, 'gender': 'female', 'name': 'Judith', 'probability': 0.98},\n",
      " {'count': 1012, 'gender': 'male', 'name': 'Stev', 'probability': 0.97},\n",
      " {'count': 245, 'gender': 'male', 'name': 'Volkmar', 'probability': 0.99},\n",
      " {'count': 4249, 'gender': 'male', 'name': 'Willi', 'probability': 0.98}]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(gender_list_btw17[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Store results in a DataFrame and save to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "btw17_gender_df = pd.DataFrame(gender_list_btw17)\n",
    "btw17_gender_df = btw17_gender_df.rename(columns = {'name':'f_name','probability':'gender_probability'})\n",
    "btw17_gender_df = btw17_gender_df[['f_name','gender','gender_probability']]\n",
    "btw17_gender_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `to_csv` defaulting to pandas implementation.\n"
     ]
    }
   ],
   "source": [
    "btw17_gender_df.to_csv('btw17_name_gender_df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Merge gender data with btw17 data and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>[' privat', 'http://www.jan-van-aken.de/', ' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>[' privat', ' bundestag', ' biografie', ' twit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>['', ' privat', ' biografie', ' bundestag', ' ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender                                        suggestions\n",
       "0   male  [' privat', 'http://www.jan-van-aken.de/', ' b...\n",
       "1   male  [' privat', ' bundestag', ' biografie', ' twit...\n",
       "2   male  ['', ' privat', ' biografie', ' bundestag', ' ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btw17_rawdata_df = btw17_rawdata_df.merge(btw17_gender_df, left_on = 'queryterm', right_on = 'f_name')[['gender','suggestions']]\n",
    "btw17_rawdata_df = btw17_rawdata_df[~btw17_rawdata_df.gender.isnull()]\n",
    "btw17_rawdata_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "btw17_rawdata_df = pd.to_csv('./btw17_rawdata_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chunksize= 10 ** 6\n",
    "chunks = pd.read_csv('./btw17_rawdata_gender.csv', usecols=['suggestions'], chunksize=chunksize)\n",
    "btw17_rawdata_df = pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get a list of all suggestion terms\n",
    "\n",
    "\n",
    "suggestion_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Dataset\n",
    "## Preprocess suggestion terms\n",
    ">*Flatten the nested list to get one big list of suggestion terms per gender*\n",
    ">\n",
    ">**Preprocessing Pipeline:**\n",
    ">- Remove punctuation\n",
    ">- Remove names from the suggestion terms to get objective terms\n",
    ">   - This includes person names and location names\n",
    ">- Only use unigrams\n",
    ">- Replace umlauts\n",
    ">- Remove digits\n",
    ">- Set strings to lowercase\n",
    ">- Remove urls\n",
    ">- Remove nltk stopwords\n",
    ">- Remove terms that consist of only 2 chars or less\n",
    ">- Strip whitespaces\n",
    ">- Remove empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../dis25-2021/cities.txt', 'r') as f:\n",
    "    locations = [term[:-1].lower() for term in f.readlines()]\n",
    "cities = pd.read_csv('../dis25-2021/Liste-Staedte-in-Deutschland.csv', delimiter=';')\n",
    "locations.extend([term.lower() for term in cities['Stadt'].to_list()])\n",
    "locations.extend([term.lower() for term in cities['Bundesland'].to_list()])\n",
    "locations.extend([term.lower() for term in cities['Landkreis'].to_list()])\n",
    "countries = pd.read_csv('../dis25-2021/csv-data.csv', delimiter=';', encoding='windows-1252')\n",
    "locations.extend([term.lower() for term in countries['Kurzform'].to_list()])\n",
    "with open('../dis25-2021/countries.txt', 'r') as f:\n",
    "    locations.extend([term[:-1].lower() for term in f.readlines()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamir', 'aaron', 'abbey', 'abbie', 'abbot', 'abbott', 'abby', 'abdel', 'abdul', 'abdulkarim', 'abdullah', 'abe', 'abel', 'abelard', 'abner', 'abraham', 'abram', 'ace', 'adair', 'adam']\n",
      "['zenia', 'zia', 'zilvia', 'zita', 'zitella', 'zoe', 'zola', 'zonda', 'zondra', 'zonnya', 'zora', 'zorah', 'zorana', 'zorina', 'zorine', 'zsa zsa', 'zsazsa', 'zulema', 'zuzana', '']\n"
     ]
    }
   ],
   "source": [
    "nltk_names = []\n",
    "with open('../dis25-2021/male.txt') as male_names_nltk:\n",
    "    nltk_names = [name.lower() for name in male_names_nltk.read().split('\\n')]\n",
    "with open('../dis25-2021/female.txt') as female_names_nltk:\n",
    "    nltk_names.extend([name.lower() for name in female_names_nltk.read().split('\\n')])\n",
    "print(nltk_names[:20])\n",
    "print(nltk_names[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.usna.edu/Users/cs/roche/courses/s15si335/proj1/files.php%3Ff=names.txt.html\n",
    "usna_names =[]\n",
    "with open('../dis25-2021/usna_names.txt') as usna_file:\n",
    "    usna_names = [name.lower() for name in usna_file.read().split('\\n')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "chunksize = 10 ** 6\n",
    "chunks = pd.read_csv(os.path.join(source_path,'suggestions_20210719.csv'), chunksize=chunksize, usecols=['queryterm'])\n",
    "btw17_df = pd.concat(chunk for chunk in chunks)\n",
    "names.extend(btw17_df.queryterm.drop_duplicates().to_list())\n",
    "\n",
    "chunksize = 10 ** 6\n",
    "for i in all_files:\n",
    "    chunks = pd.read_csv(i,\n",
    "                         header=None,\n",
    "                         names=['id','queryterm','date','client','lang','url','raw_data'],\n",
    "                         usecols=['queryterm'],\n",
    "                         chunksize=chunksize)\n",
    "    temp_df = pd.concat(chunks)\n",
    "    names.extend(temp_df.queryterm.drop_duplicates().to_list())\n",
    "\n",
    "names = list(set(names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## get a list of names\n",
    "names = [subname.strip('()').lower() for name in names for subname in name.split() if len(subname) > 2]\n",
    "names.extend(nltk_names)\n",
    "names.extend(usna_names)\n",
    "names.extend(locations)\n",
    "names = list(set(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "with open(\"./all_names_to_delete.txt\", \"w\",encoding=\"utf-8\") as textfile:\n",
    "    for element in names:\n",
    "        textfile. write(element + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load german dictionary file\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aachen', 'aachener', 'aachenerin', 'aachenerinnen', 'aachenern', 'aacheners', 'aachens', 'aal', 'aalähnlich', 'aalähnliche', 'aalähnlichem', 'aalähnlichen', 'aalähnlicher', 'aalähnliches', 'aalangelfischerei', 'aalangeln', 'aalangelns', 'aalartig']\n"
     ]
    }
   ],
   "source": [
    "with open('../dis25-2021/wordlist-german.txt', 'r', encoding='utf-8') as f:\n",
    "    german_terms = [term[:-1].lower() for term in f.readlines()]\n",
    "print(german_terms[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Perform Preprocessing and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delete_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20112/2774161181.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msuggestion_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgerman_terms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgerman_terms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\dis25\\functions.py\u001B[0m in \u001B[0;36mpreprocess\u001B[1;34m(self, suggestions, german_terms)\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mgerman_terms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m->\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranslate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmaketrans\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpunctuation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m' '\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpunctuation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_pattern\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelete_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mterm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mterm\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msuggestions\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0msuggestion\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msuggestion\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msuggestions\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msuggestion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\dis25\\functions.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpreprocess\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mgerman_terms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m->\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranslate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmaketrans\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpunctuation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m' '\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpunctuation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_pattern\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdelete_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mterm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mterm\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msuggestions\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0msuggestion\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msuggestion\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msuggestions\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msuggestion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[0msuggestions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msuggestions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'delete_names' is not defined"
     ]
    }
   ],
   "source": [
    "suggestions = preprocessing.preprocess(preprocessing,suggestions=suggestion_list, german_terms=german_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaktionsanalyse', 'wissenschaftsministerium', 'ehrenerklärung', 'zentralabitur', 'jugendreferent', 'elektronik', 'kaufoption', 'trainerschein', 'physiotherapie', 'herzfehler']\n"
     ]
    },
    {
     "data": {
      "text/plain": "5255"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(suggestions[:10])\n",
    "len(suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "textfile = open(\"./suggestion_terms_NN.txt\", \"w\",encoding=\"utf-8\")\n",
    "for element in suggestions:\n",
    "    textfile. write(element + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}